# user-item-embedding-pipeline
# user-item-embedding-pipeline  
> Построение shared embedding space для пользователей и товаров (Ozon Hackathon)

Проект реализован в команде из 3 человек.  
**Моя роль**:  
обработка сырых логов (6M+ айтемов, миллионы пользователей),  
глубокий анализ и инжиниринг фичей,  
построение мультимодальных эмбеддингов товаров (fCLIP + текст + атрибуты + иерархия + популярность),  
обучение two-tower модели для отображения истории пользователя и айтемов в общее пространство эмбеддингов.

---

## Что я сделал

### Анализ и feature engineering
- **Анализ популярности**: проверка закона Ципфа, z-score, tailness, нормализованные ранги → 9 фич для каждого `model_id`.
- **Атрибуты товаров**: фильтрация редких значений, преобразование в sparse multi-hot → добавление флагов `no_{attr}` / `other_{attr}`.
- **Категории**: построение подграфа одежды → обучение **Poincaré embeddings** (15d, Hit@1 = 0.72) для сохранения иерархической структуры.

### Эмбеддинги айтемов
- `multi-hot` → `TruncatedSVD` (70 компонент, 95%+ дисперсии)  
- `fCLIP` + внешние текстовые эмбеддинги (агрегация по `item_id`)  
- объединение:  
  `[SVD feats \| norm(zipf) \| norm(Poincaré) \| norm(fCLIP)] + text embeds` → **326-мерный вектор**

### Two-tower модель
- **User tower**:  
  - GRU над последовательностью `[item_embed \| user_features]`  
  - временные фичи: `velocity`, `acceleration`, `hour sin/cos`  
  - поведенческие сигналы: `success/failure` по паттернам (например, `to_cart` → `cart.total`)  
  - attention mask для padding
- **Item tower**: 2-слойный MLP  
- **Loss**: Pairwise Logistic Ranking (positive = `delivered`, negative = `canceled` + failure items)

### Инженерия масштаба
- обработка чанками через `polars`,  
- sparse → dense только при необходимости,  
- кастомный `IterableDataset` с lazy loading,  
- memory control (`gc.collect()`, `torch.cuda.empty_cache()`),  
- multi-worker `DataLoader`.

---

## Результаты и рефлексия

- Loss стабильно снижался во время fine-tuning (→ -38% за 50 эпох)  
- Финальный скор: **0.0007** при лидирующем **0.088**  

**Причины (постфактум)**:
- крайне редкие позитивы (`delivered_orders` — <1% событий),  
- слабые негативы (случайные айтемы почти всегда тривиальны),  
- возможна ошибка размерности: модель ожидала 128d, но получала 326d → обрезка без нормировки.

> **Ключевой вывод**: в large-scale retrieval качество сигналов (labels, negatives) часто важнее архитектуры. Теперь я начинаю с A/B-теста стратегий формирования таргета.

---

## Стек
`Python` `PyTorch` `Polars` `scikit-learn` `Gensim (Poincaré)` `NetworkX` `scipy.sparse` `joblib`

---

> Проект демонстрирует:  
> • умение работать с нетривиальными данными промышленного масштаба,  
> • research-мышление (анализ распределений, геометрические эмбеддинги),  
> • инженерную зрелость (memory-safe pipeline),  
> • понимание пользовательского поведения за пределами item ID.
